---
output:
  word_document:
    reference_docx: ../MPFF report template v1.1.dotx
---


```{r setup, include=FALSE}

# ==========================================================================================================
# Generate FLYSHOOT project overview
# 
# 8/3/2023 first coding
# ==========================================================================================================

knitr::opts_chunk$set(echo = FALSE,	message = FALSE,	warning = FALSE,	comment = "",	crop = TRUE )
knitr::opts_chunk$set(fig.width=10) 

options(dplyr.summarise.inform = FALSE)

# Reset lists
rm(list=ls())

# Libraries
library(rmarkdown)                   # note: requires knitr 1.21

require(tidyverse, quietly=TRUE)     # combined package of dplyr, tidyr, ggplot, readr, purrr and tibble
require(lubridate, quietly=TRUE)     # data handling
require(reshape2, quietly=TRUE)      # reshaping data; e.g. cast
require(RColorBrewer)                # colour schemes
library(viridis)
library(pander)

library(captioner)                   # for captions
tab_nums <- captioner::captioner(prefix = "Table " , levels=1, type=c("n"), infix=".")
fig_nums <- captioner::captioner(prefix = "Figure ", levels=1, type=c("n"), infix=".")

# Source all the utils
source("../../prf/R/my utils.r")

get_onedrive <- function (team="Martin Pastoors", site="FLYSHOOT - General") {
  
  if (Sys.info()['sysname'] == 'Windows') {
    
    # set onedrive directory
    if(dir.exists(file.path(Sys.getenv('USERPROFILE'), team, site))) {
      onedrive <- file.path(Sys.getenv('USERPROFILE'), team, site)   
    } else if(dir.exists(file.path('C:/DATA/PFA', team, site))) {
      onedrive <- file.path('C:/DATA/PFA', team, site)
    } else if(dir.exists(file.path('D:/DATA/PFA', team, site))) {
      onedrive <- file.path('D:/DATA/PFA', team, site)
    } else {
      stop("Onedrive directory not found")
    }
  }
  
  return(onedrive)
}

spatialdir <- "C:/DATA/RDATA"

# spatial data files

load(file.path(spatialdir, "world_mr_sf.RData"))
load(file.path(spatialdir, "rect_lr_sf.RData"))

load(file.path(spatialdir, "world_lr_df.RData"))

load(file.path(spatialdir, "afsis.RData"))

# ===============================================================================
#  Load and filter the trip data
# ===============================================================================

# set onedrive directory
onedrive <- get_onedrive(team="Martin Pastoors", site="FLYSHOOT - General")

# load datasets
haul   <- loadRData(file.path(onedrive, "rdata/haul.RData"))
kisten <- loadRData(file.path(onedrive, "rdata/kisten.RData")) 
elog   <- loadRData(file.path(onedrive, "rdata/elog.RData")) %>% 
  mutate(species = toupper(species)) %>% 
  mutate(species = ifelse(species=="JAX","HOM",species))

yrs     <- 2012:2023
mnths   <- NA
vessels <- NA

myyear <- max(yrs)

# making the data selections
h <- 
  haul %>%
  ungroup() %>% 
  {if(!is.na(all(vessels))) filter(., vessel %in% vessels) else . } %>% 
  {if(!is.na(all(yrs)))     filter(., year %in% yrs) else . } %>% 
  {if(!is.na(all(mnths)))   filter(., month %in% mnths) else .} %>% 
  ungroup()

k <- 
  kisten %>%
  mutate(
    year  = lubridate::year(datetime),
    month = lubridate::month(datetime)
  ) %>% 
  ungroup() %>% 
  {if(!is.na(all(vessels))) filter(., vessel %in% vessels) else . } %>% 
  {if(!is.na(all(yrs)))     filter(., year %in% yrs) else . } %>% 
  {if(!is.na(all(mnths)))   filter(., month %in% mnths) else .} %>% 
  mutate(haul = ifelse(is.na(haul), haul2, haul))

e <- 
  elog %>%
  ungroup() %>% 
  {if(!is.na(all(vessels))) filter(., vessel %in% vessels) else . } %>% 
  {if(!is.na(all(yrs)))     filter(., year %in% yrs) else . } %>% 
  {if(!is.na(all(mnths)))   filter(., month %in% mnths) else .} %>% 
  ungroup() %>% 
  mutate(species = tolower(species)) %>% 
  mutate(species = ifelse(species == "SQR", "SQC", species)) %>% 
  left_join(dplyr::select(afsis,
                          species, scientific_name, english_name, dutch_name),
            by = "species") %>% 
  mutate(species = toupper(species))  

# calculate the scaling of plots
xmin <- floor(2 * (min(e$lon, na.rm=TRUE)-0.5))/2;
xmax <- ceiling(2 * (max(e$lon, na.rm=TRUE)+0.5))/2;
ymin <- floor(2 * (min(e$lat, na.rm=TRUE)-0.5))/2;
ymax <- ceiling(2* (max(e$lat, na.rm=TRUE)+0.5))/2

n <- 15

effort <-
  e %>% 
  dplyr::group_by(vessel, year) %>% 
  dplyr::summarize(ndays = n_distinct(paste(vessel, date))) 

catch <-
  e %>% 
  dplyr::group_by(vessel, year, species, 
                  scientific_name, english_name, dutch_name) %>% 
  dplyr::summarize(weight = sum(weight, na.rm=TRUE)) %>% 
  dplyr::group_by(vessel, year) %>% 
  dplyr::mutate(perc = weight/sum(weight, na.rm=TRUE)) %>% 
  left_join(effort, by=c("vessel", "year")) %>% 
  mutate(catch_day = weight / ndays)

top <-
  catch %>% 
  filter(year == max(yrs)) %>% 
  dplyr::group_by(species) %>% 
  dplyr::summarize(weight     = sum(weight, na.rm=TRUE)) %>% 
  arrange(desc(weight)) %>% 
  slice_head(n=n)


```


**FLYSHOOT project overview**

For: Jaczon BV

By: Martin Pastoors

Version: 1.0 `r format(Sys.time(), '%d %B %Y')`

<br> 

<br> 

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

<br>

```{r, echo=FALSE, out.width = "200px", fig.align="right", message=FALSE, warning=FALSE, cache=FALSE}

knitr::include_graphics("../MPFF logo with text wide right align.png")

```

\newpage

**Executive summary**

The project between Jaczon BV and Martin Pastoors F&F started in January 2023 and is already leading to large steps in innovation. Haul by haul data is now routinely collected on the four flyshoot vessels. There are couplings with the Marelec data and with the electronic logbook data. The skippers are actively involved in the data collection and getting feedback on their own data. 

The automated coupling of Marelec weighing, GPS, time and the PEFA logbook has been initiated and is close to being finalized. 

The assessment of the total catch per haul with a rules in the hopper is not working as anticipated. A new approach has been chosen together with Marelec to use a tension approach for weighing the total net before it is empties. This will be trialled in April/May 2023

The recording and analysis of bycatch data is still under development. This could be approached via a REM approach (Archipelago, Anchor lab, ...) or via a camerabox approach (WUR Fully Documented Fishery). 

Historical electronic logbook data has been made available from backups on the vessels. These still need to be analysed on catch rates. 

Survey data relevant to the flyshoot fishery is being made available via a project parallel to the current Flyshoot project. This is expected to become available in the near future and can give information on the trends in different stocks. 


\newpage

# Introduction

In order to improve the assessment of the sustainability of the flyshoot fishery, Jaczon BV has commissioned Martin Pastoors F&F to carry out the following tasks: 

1. Set-up and supervise self-sampling on flyshoot fishing vessels and carry out analysis and reporting on self-sampling data for target species and bycatch. 

2. Organise access to historical and ongoing electronic logbook data and carry out analysis and report on trends in catch rates and spatio-temporal dynamics. 

3. Create an inventory of available scientific surveys in the North Sea and English Channel and carry out analysis and report on population trends for various target species of the flyshoot fishery.

This report provides an overview of the activities and achievements by `r format(Sys.time(), '%d %B %Y')`.

# Data collection on flyshoot fishing vessels

## Self-sampling

Self-sampling is method to collect data onboard of fishing vessels by the crews of the vessel and any equipment that is already avaible. Self-sampling in the flyshoot fishery was initiated with Martin Pastoors joining the first trip of 2023 of the vessel SCH65 Simplon (2-5 January 2023). During that trip, an assessment was made of the way the fishery was being persecuted, the handling of the fish onboard and the equipment being used. A trial version of a self-sampling spreadsheet was developed and adapted during the trip. The self-sampling spreadsheet was then handed out to the skippers of the other flyshoot vessels (SCH135 Galibier, SL9 Johanna and Z99 Aravis). 

From the initial trip, it became clear that there were already a number of data-collection mechanisms on the vessels that could be used as part of the self-sampling program:

* The Marelec weighing scales could be used to generate an export of all the boxes that had been weighed during the trip. This would provide an detailed estimate of the landings by species.  
* The PEFA electronic logbook could be used to generate an export on the catch per species, per day and per ICES rectangle. 
* The estimate of total catch could possibly be derived from the measuring scale in the hopper, that has been installed by WMR on the vessels (except for Z99). 

An overview of the self-sampling activities to date is presented in the table below: 

```{r triptable, echo=FALSE, message=FALSE, warning=FALSE, comment=NA, fig.asp=0.6}

tab_nums(name    = "trips", level = 1, display = FALSE, caption = "Self-sampling overview")

t <-
  bind_cols(
    h %>% 
      filter(year %in% myyear) %>% 
      group_by(year, month) %>% 
      summarise(
        nvessels      = n_distinct(vessel),
        ntrips        = n_distinct(paste(vessel, trip)),
        ndays         = n_distinct(paste(vessel, trip, date)),
        nhauls        = n_distinct(paste(vessel, trip, haul)),
        nrects        = n_distinct(rect),
        # nlandedcatch  = sum(!is.na(landingweight)),
        ntotalcatch   = sum(!is.na(totalcatch))
      ),
    k %>% 
      filter(year %in% myyear) %>% 
      group_by(vessel, trip, haul, year, month) %>% 
      summarise(gewicht = sum(gewicht, na.rm=TRUE)) %>% 
      group_by(year, month) %>% 
      summarise(
        nlandedcatch  = sum(!is.na(gewicht)),
        landedcatch   = sum(gewicht)
      ) %>% 
      ungroup() %>% 
      dplyr::select(-year, -month),
    # discard ratio (when observed)
    k %>% 
      filter(year %in% myyear) %>% 
      group_by(vessel, trip, haul, year, month) %>% 
      summarise(gewicht = sum(gewicht, na.rm=TRUE)) %>% 
      left_join(h, by=c("vessel","trip","haul", "year", "month")) %>% 
      filter(!is.na(totalcatch)) %>% 
      group_by(year, month) %>% 
      summarise(
        landedcatch   = sum(gewicht, na.rm=TRUE),
        totalcatch    = sum(totalcatch, na.rm=TRUE)
      ) %>% 
      mutate(discardperc = scales::percent(1-(landedcatch/totalcatch))) %>% 
      ungroup() %>% 
      dplyr::select(-year, -month, -landedcatch, -totalcatch)
  )  %>% 
    mutate(year=as.character(year), month=as.character(month)) 

t2 <-
  t %>% 
  ungroup() %>% 
  summarise(
    ndays = sum(ndays),
    nhauls = sum(nhauls),
    ntotalcatch = sum(ntotalcatch),
    nlandedcatch = sum(nlandedcatch),
    landedcatch = sum(landedcatch)
  ) %>% 
  mutate(year = as.character(myyear)) %>% 
  mutate(month = "all")

bind_rows(t, t2) %>% 
  pander::pandoc.table(., 
               style        = "simple",
               split.tables = 200, 
               split.cells  = c(rep(7,10)),
               justify      = "right",
               missing      =" ",
               big.mark     = ',', 
               round        = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0) )

  


```

_`r tab_nums("trips")`_

The discards percentage is calculate on the basis of those hauls for which both total catch and landed catch is available. Analysis has shown that the estimation of total catch in the hopper is very uncertain, especially in case of small catch volumes. Therefore, the percentage discards is unlikely to be a realistic estimate (see below). 


The catch composition by species is derived from the electronic logbook reports by vessel. The reports cover more trips than the the self-sampling per se, because vessels started to collect haul-by-haul information incrementally over the start of 2023. 

```{r trips, echo=FALSE, message=FALSE, warning=FALSE, comment=NA, fig.asp=0.6}

tab_nums(name    = "species", level = 1, display = FALSE, caption = "Self-sampling: landings by species")

myyear    <- 2023
myspecies <- as.character(slice_head(top, n=10)$species)

t <-
  e %>% 
  filter(year %in% myyear) %>% 
  mutate(species = ifelse(species %in% myspecies, species, "OTH")) %>% 
  mutate(species = factor(species, levels=c(myspecies,"OTH"))) %>% 
  group_by(year, month, species) %>% 
  summarise(catch = sum(weight, na.rm=TRUE)) %>% 
  reshape2::dcast(year+month ~ species, value.var = "catch", sum, margins=c("month","species"))

  
t %>% 
  mutate(year=as.character(year)) %>% 
  pander::pandoc.table(., 
               style        = "simple",
               split.tables = 200, 
               split.cells  = c(rep(7,10)),
               justify      = "right",
               missing      =" ",
               big.mark     = ',', 
               round        = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0) )

  


```
_`r tab_nums("species")`_

## Assessment of the total catch per haul

The assessment of the total catch by haul has so far been implemented on SCH65, SCH135 and SL9, where WMR has installed rulers in the hopper. The rulers were intended to be used for either the whole hopper or a smaller subsection of the hopper. However, in practice, it is not feasible to utilize the subsectioned hopper because of the difficult handling procedures required. When using the whole hopper, the scale is very imprecise leading to frequent occasions when the total catch is small than the landed catch for a haul (see figure below). 

To address this issue, a new approach is being explored in collaboration with Marelec. A pull measurement system will be installed on the Z99 Aravis, that will allow a measurement of the weight of the total catch just before the codend is empties into the hopper. It is anticipated that the new system will be available in April/May 2023. 
```{r aanvoerendiscards, echo=FALSE, fig.align="center", fig.asp=0.8, message=FALSE, warning=FALSE}

fig_nums(
  name    = "landedandtotalcatch", level   = 1, display = FALSE,
  caption = "Landed catch and total catch per day and vessel")

t1 <-
  h %>% 
  filter(year == 2023, vessel != "Z99") %>% 
  group_by(vessel, trip, date) %>% 
  summarise(totalcatch = sum(totalcatch, na.rm=TRUE)) 

t2 <-
  k %>% 
  mutate(date = as.Date(datetime)) %>% 
  mutate(year = lubridate::year(date)) %>%
  filter(year == 2023, vessel != "Z99") %>% 
  group_by(vessel, trip, date) %>% 
  summarise(landedcatch = sum(gewicht, na.rm=TRUE)) 
  
left_join(t1, t2) %>% 
  drop_na(totalcatch, landedcatch) %>% 
  pivot_longer(names_to = "variable", values_to = "data", c(totalcatch, landedcatch)) %>% 
  
  ggplot(aes(x=date, y=data)) +
  theme_publication() +
  # theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  geom_bar(aes(fill=variable),
           # stat="identity", position=position_dodge(), alpha=0.8, width=0.5, just=0.8) +
           stat="identity", position=position_dodge(), alpha=0.8, width=0.9) +
  # scale_x_continuous(breaks=seq(1,max(t1$haul, m$haul, na.rm=TRUE), 1)) +
  labs(x="", y="kg", title="landed catch and total catch per day") +
  facet_grid(vessel~., scales="free_y")
    


```

## Monitoring of bycatch

Monitoring of bycatch is an important topic for the Flyshoot fishery. Within the reseach project with the GoodFish foundation and WMR, bycatch has been monitored with the use of observers during 10-12 trips. While this delivers high quality bycatch data, it does not provide sufficient coverage of the fishery. Some examples of bycatches during trip 235 of SCH65 are shown in the figure below. During that trip, observations over the conveyor belt were generated using a GoPro system, mounted on the control box. However, it was found that this system, while delivering high quality video material, was not sufficiently robust to implement on a lasting basis. It was also clear, that it would not be feasible to request this type of work to be carried out by the crew. 
  

```{r, echo=FALSE, fig.align="right", message=FALSE, warning=FALSE, cache=FALSE}

knitr::include_graphics("C:/Users/MartinPastoors/Martin Pastoors/FLYSHOOT - General/pictures/Screenshot 2023-03-08 141653.png")

```

Therefore, it is recommended to explore professional solutions to collect and analyse data on bycatch. This involves three main steps: 

1. hardware for data capture
2. data upload and storage
3. data analysis (manual / automated)

In collaboration with Niels Bruggenkamp, contact has been made with the party that is handling the CCTV solutions for Vrolijk BV (C4U, Breda) who have installed the CCTV system for the Aravis. C4U suggested installing an extra Axis Q3538 SLV camera over the conveyor belt. This only addresses step 1 above. 

A talk has been initiated with Archipelago Marine Research (https://www.archipelago.ca/) who have a wide range of expertise in Remote Electronic Monitoring for many different fisheries. For the purpose that was explained to them, they suggested a two step approach: 1) to start with a mobile version of a data capture, upload and analysis tool. This would require a standard (but rugged) tablet device for the data capture. 2) opt for a Archipelago 'micro' system that is going to be launched in spring 2023 and which will have one or two fixed camera's in conjuction with several potential sensors (including GPS, sensor on the conveyor belt). The analysis will initially still need to be done with semi-automated methods. 

The best solution would be if the analysis of bycatch data could be done automatically. There is substantial progress in this direction via the Fully Documented Fisheries project that WUR is carrying out. They are working either with a CCTV system, but more importantly with a fixed camera box (see below). 

```{r, echo=FALSE, fig.align="right", message=FALSE, warning=FALSE, cache=FALSE}

knitr::include_graphics("C:/Users/MartinPastoors/Martin Pastoors/FLYSHOOT - General/pictures/fdf camerabox.png")

```

The FDF consortium is currently putting together a new project bid in which they want to include the flyshoot fishery, so this could be an interesting solution for our case.  

## Tripreports

Tripreports are being generated at the completion of each trip and of each vessel. 

```{r, echo=FALSE, fig.align="right", message=FALSE, warning=FALSE, cache=FALSE}

knitr::include_graphics("C:/Users/MartinPastoors/Martin Pastoors/FLYSHOOT - General/pictures/Tripreport.png")

```

# Electronic logbook data, additional data capture and CPUE analyses

Electronic logbook data has been made available via the backups available of the vessels. Several systems have been used in the past and present (OLRAC, ECATCH, MCATCH, PEFA). Via dedicated code that was written by Martin Pastoors, it has been possible to read in the old OLRAC and ECATCH data for the vessels and years when backup data was available (SL9 and SCH65, from 2012 onwards) Recent electronic logbooks data is being downloaded for each trip, from the PEFA system (SCH65, SCH135 and SL9) and the M-Catch system (Z99). The number of fishing days for which logbook data is now available is shown in the figure below. 

```{r visdagen, echo=FALSE, message=FALSE, warning=FALSE, comment=NA, fig.asp=0.6}

fig_nums(
  name    = "fishingdays", 
  level = 1, display = FALSE,
  caption = "Total number of fishing days in electronic logbook data")

effort %>% 
  ggplot(aes(x=year, y=ndays)) +
  theme_publication() +
  geom_bar(aes(fill=vessel), stat="identity") +
  scale_x_continuous(breaks=seq(min(effort$year), max(effort$year),1))


```

_`r fig_nums("fishingdays")`_

## Modifications to the electronic logbook data

In collaboration with PEFA, the export facilities from the PEFA logbook system have been expanded. 

1. An export routine has been added to export the raw data entered into the logbook (i.e. catch by species, rectangle and day)
2. A coupling has been generated between the Marelec weighing system, the GPS and the PEFA electronic logbook. While not working 100% yet, it is anticipated that this will be able to generate an export file for each box, with a georeference (GPS), time, species and weight. Some initial hickups are still being ironed out at present. 

In principle this development could do away with most of the additional input that is currently required in the self-sampling list. 

# Scientific surveys in the English Channel and North Sea

While the work on scientific surveys in the English Channel and North Sea has commenced already, there are still a number of important steps to be taken. 

Next to the project with Jaczon BV, and as a service to the community of fisheries scientists and stakeholders, Martin Pastoors has been working with Einar Hjorleifsson (Iceland) on the development of a Shiny app with which the ICES survey data will be made available to a wider audience. While currently only operational for the North Sea Quarter 3 IBTS survey, the intention is that this will be developed for all surveys in the ICES Datras database. For the Flyshoot fishery the three most relevant surveys are the IBTS Q1, IBTS Q3 and CGFS Q4 surveys.  
```{r, echo=FALSE, out.width = "400px", fig.align="right", message=FALSE, warning=FALSE, cache=FALSE}

knitr::include_graphics("C:/Users/MartinPastoors/Martin Pastoors/FLYSHOOT - General/pictures/Shiny1.png")

```


```{r, echo=FALSE, out.width = "400px", fig.align="right", message=FALSE, warning=FALSE, cache=FALSE}

knitr::include_graphics("C:/Users/MartinPastoors/Martin Pastoors/FLYSHOOT - General/pictures/Shiny1.png")

```

# Other activities

At the request of Jaczon BV, Martin Pastoors has participated in the regular project meeting of the GoodFish/WMR/Jaczon Flyshoot project. 

# Discussion and outlook

The project between Jaczon BV and Martin Pastoors F&F started in January 2023 and is already leading to large steps in innovation. Haul by haul data is now routinely collected on the four flyshoot vessels. There are couplings with the Marelec data and with the electronic logbook data. The skippers are actively involved in the data collection and getting feedback on their own data. 

The automated coupling of Marelec weighing, GPS, time and the PEFA logbook has been initiated and is close to being finalized. 

The assessment of the total catch per haul with a rules in the hopper is not working as anticipated. A new approach has been chosen together with Marelec to use a tension approach for weighing the total net before it is empties. This will be trialled in April/May 2023

The recording and analysis of bycatch data is still under development. This could be approached via a REM approach (Archipelago, Anchor lab, ...) or via a camerabox approach (WUR Fully Documented Fishery). 

Historical electronic logbook data has been made available from backups on the vessels. These still need to be analysed on catch rates. 

Survey data relevant to the flyshoot fishery is being made available via a project parallel to the current Flyshoot project. This is expected to become available in the near future and can give information on the trends in different stocks. 

To pick up in the near future: 

* Finalizing the coupling between Marelec weighing, GPS and PEFA logbook (similar for M-Catch?)
* Camera observation and analysis of bycatch data (trial on Aravis?)
* Implementation of the weighing system for the total catch (Aravis)
* CPUE analysis based on electronic logbook data
* Survey trends in the Channel and Southern North Sea

# Annex

**Haullist summary by trip**

```{r echo=FALSE, message=FALSE, warning=FALSE, comment=NA}

tab_nums(
  name    = "h", 
  level = 1, display = FALSE,
  caption = "Samenvatting van de trekgegevens")

# summarize the haul information
hh <- 
  h %>%
  group_by(vessel,trip) %>%
  summarise(
    nhauls            = n(),
    startdate         = min(date, na.rm=TRUE),
    enddate           = max(date, na.rm=TRUE),
    weeks             = paste(unique(week), collapse=","),
    months            = paste(unique(month), collapse=","),
    divisions         = paste(unique(division), collapse=";"),
    rects             = paste(unique(rect), collapse=";"),
  ) %>% 
  mutate (
    ndays             = as.numeric(difftime(enddate, startdate, units="days")) + 1,
    haulsperday       = nhauls/ndays
  ) 


hh %>% 
  group_by(vessel) %>% 
  do(add_row(., .after=0)) %>%
  pandoc.table(.,
             style = "simple",
             split.tables=400, 
             justify = "left",
             missing=".",
             round=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))

```

_`r tab_nums("h")`_

\newpage

**Summary of the Marelec data**

```{r echo=FALSE, message=FALSE, warning=FALSE, comment=NA}

tab_nums(
  name    = "m", 
  level = 1, display = FALSE,
  caption = "Summary of the Marelec data")

# summarize the kisten informatie
mm <- 
  k %>%
  group_by(vessel,trip) %>%
  summarise(
    nkisten           = n(),
    nsoorten          = n_distinct(soorten),
    startdate         = as.Date(min(datetime, na.rm=TRUE)),
    enddate           = as.Date(max(datetime, na.rm=TRUE)),
    weeks             = paste(unique(week(datetime)), collapse=","),
    months            = paste(unique(month(datetime)), collapse=","),
    gewicht           = sum(gewicht, na.rm=TRUE)
  ) %>% 
  mutate (
    ndays             = as.numeric(difftime(enddate, startdate, units="days")) + 1
  ) 


mm %>% 
  group_by(vessel) %>% 
  do(add_row(., .after=0)) %>%
  pandoc.table(.,
             style = "simple",
             split.tables=400, 
             justify = "left",
             missing=".",
             round=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))

```

_`r tab_nums("m")`_

\newpage

# elog information

```{r echo=FALSE, message=FALSE, warning=FALSE, comment=NA}

tab_nums(
  name    = "e", 
  level = 1, display = FALSE,
  caption = "Samenvatting van de elog gegevens")

# summarize the elog informatie
ee <- 
  e %>%
  filter(year %in% myyear) %>% 
  group_by(vessel,trip) %>%
  summarise(
    startdate         = min(date, na.rm=TRUE),
    enddate           = max(date, na.rm=TRUE),
    weeks             = paste(unique(week), collapse=","),
    months            = paste(unique(month), collapse=","),
    divisions         = paste(unique(faozone)[!is.na(unique(faozone))], collapse=";"),
    rects             = paste(unique(rect)[!is.na(unique(rect))], collapse=";"),
    nsoorten          = n_distinct(species),
    gewicht           = sum(weight, na.rm=TRUE)
  ) %>% 
  mutate (
    ndays             = as.numeric(difftime(enddate, startdate, units="days")) + 1
  ) 


ee %>% 
  group_by(vessel) %>% 
  do(add_row(., .after=0)) %>%
  pandoc.table(.,
             style = "simple",
             split.tables=400, 
             justify = "left",
             missing=".",
             round=c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0))

```

\newpage

 **Combined look at different data sources by vessel and trip**
 
```{r echo=FALSE, message=FALSE, warning=FALSE, comment=NA, fig.asp=0.6}

fig_nums(
  name    = "c", 
  level = 1, display = FALSE,
  caption = "Combined look at different data sources by vessel and trip")

hh <- 
  h %>%
  group_by(vessel,trip) %>%
  summarise(
    nhauls            = n(),
    startdate         = min(date, na.rm=TRUE),
    enddate           = max(date, na.rm=TRUE),
    weeks             = paste(unique(week), collapse=","),
    months            = paste(unique(month), collapse=","),
    divisions         = paste(unique(division), collapse=";"),
    rects             = paste(unique(rect), collapse=";"),
  ) %>% 
  mutate (
    ndays             = as.numeric(difftime(enddate, startdate, units="days")) + 1,
    haulsperday       = nhauls/ndays
  ) 

kk <- 
  k %>%
  group_by(vessel,trip) %>%
  summarise(
    nkisten           = n(),
    nsoorten          = n_distinct(soorten),
    startdate         = as.Date(min(datetime, na.rm=TRUE)),
    enddate           = as.Date(max(datetime, na.rm=TRUE)),
    weeks             = paste(unique(week(datetime)), collapse=","),
    months            = paste(unique(month(datetime)), collapse=","),
    gewicht           = sum(gewicht, na.rm=TRUE)
  ) %>% 
  mutate (
    ndays             = as.numeric(difftime(enddate, startdate, units="days")) + 1
  ) 

ee <- 
  e %>%
  filter(year %in% myyear) %>% 
  group_by(vessel,trip) %>%
  summarise(
    startdate         = min(date, na.rm=TRUE),
    enddate           = max(date, na.rm=TRUE),
    weeks             = paste(unique(week), collapse=","),
    months            = paste(unique(month), collapse=","),
    divisions         = paste(unique(faozone), collapse=";"),
    rects             = paste(unique(rect), collapse=";"),
    nsoorten          = n_distinct(species),
    gewicht           = sum(weight, na.rm=TRUE)
  ) %>% 
  mutate (
    ndays             = as.numeric(difftime(enddate, startdate, units="days")) + 1
  ) 

# summarize the trip informatie
comb <-
  bind_rows(
    hh %>% mutate(source="haul"),
    kk %>% mutate(source="marelec"),
    ee %>% mutate(source="elog")
  )

comb %>% 
  dplyr::select(vessel, trip, startdate, enddate, source) %>% 
  mutate(source = factor(source, levels=c("haul", "marelec", "elog"))) %>% 
  mutate(trip = gsub("^2023","", trip)) %>% 
  
    # selfsampling bars
  ggplot() +
  theme_publication() +
  ggalt::geom_dumbbell(aes(x = startdate, xend = enddate, y=source, group=1, colour=source),
                       size=3, size_x = 0, size_xend = 0, alpha=0.4) +
  geom_text(aes(x = startdate, y=source, label=trip), hjust=0) +
  facet_grid(vessel~.)

```

_`r fig_nums("c")`_

<!-- ########################################################################################## -->
<!-- Table: vangst --------------------------- -->
<!-- ########################################################################################## -->
